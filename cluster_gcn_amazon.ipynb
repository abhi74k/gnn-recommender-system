{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.loader import ClusterData, ClusterLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>also_bought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26843</th>\n",
       "      <td>B0006AAS7E</td>\n",
       "      <td>B000GX8WAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26844</th>\n",
       "      <td>B0006AAS7E</td>\n",
       "      <td>B000JQJS6W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26845</th>\n",
       "      <td>B0006AAS7E</td>\n",
       "      <td>B000GX8W2O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26846</th>\n",
       "      <td>B0006AAS7E</td>\n",
       "      <td>B00FALPXLU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26847</th>\n",
       "      <td>B0006AAS7E</td>\n",
       "      <td>B00LSYRUVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             asin also_bought\n",
       "26843  B0006AAS7E  B000GX8WAG\n",
       "26844  B0006AAS7E  B000JQJS6W\n",
       "26845  B0006AAS7E  B000GX8W2O\n",
       "26846  B0006AAS7E  B00FALPXLU\n",
       "26847  B0006AAS7E  B00LSYRUVE"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_co_purchase_df = pd.read_csv('kcore70_title_imurl.csv', index_col=0)\n",
    "processed_co_purchase_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AsinIdMap:\n",
    "    def __init__(self, asin_list):\n",
    "        self.asin_list = asin_list\n",
    "        self.asin_to_idx = {}\n",
    "        self.product_idx_to_asin = {}\n",
    "        self._build()\n",
    "    \n",
    "    def _build(self):\n",
    "        for idx, asin in enumerate(self.asin_list):\n",
    "            self.asin_to_idx[asin] = idx\n",
    "            self.product_idx_to_asin[idx] = asin\n",
    "    \n",
    "    def get_idx(self, asin):\n",
    "        return self.asin_to_idx[asin]\n",
    "    \n",
    "    def get_asin(self, product_idx):\n",
    "        return self.product_idx_to_asin[product_idx]\n",
    "    \n",
    "    def get_count(self):\n",
    "        return len(self.asin_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "asin_list = list(processed_co_purchase_df['asin'].unique())\n",
    "also_bought_list = list(processed_co_purchase_df['also_bought'].unique())\n",
    "asin_list.extend(also_bought_list)\n",
    "asin_list = list(set(asin_list))\n",
    "asinIdLookup = AsinIdMap(asin_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge shape:  torch.Size([2, 120987])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "def build_product_to_product_edge_index(edges_pd, asin_id_map, right_key):\n",
    "    product_to_product_edge_index = []\n",
    "    for idx, row in edges_pd.iterrows():\n",
    "            asin1 = row['asin']\n",
    "            product1_idx = asin_id_map.get_idx(asin1)\n",
    "            asin2 = row[right_key]\n",
    "            product2_idx = asin_id_map.get_idx(asin2)\n",
    "            if product1_idx == product2_idx:\n",
    "                continue\n",
    "            product_to_product_edge_index.append([product1_idx, product2_idx])\n",
    "\n",
    "    return torch.tensor(product_to_product_edge_index).t().contiguous()\n",
    "\n",
    "product_feature_dim = 128\n",
    "num_products = len(asin_list)\n",
    "x = torch.randn(num_products, product_feature_dim)\n",
    "edge_index = build_product_to_product_edge_index(processed_co_purchase_df, asinIdLookup, 'also_bought')\n",
    "print(\"Edge shape: \", edge_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import to_undirected\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "data.edge_index = to_undirected(data.edge_index)\n",
    "\n",
    "# For this, we first split the set of edges into\n",
    "# training (80%), validation (10%), and testing edges (10%).\n",
    "# Across the training edges, we use 70% of edges for message passing,\n",
    "# and 30% of edges for supervision.\n",
    "# We further want to generate fixed negative edges for evaluation with a ratio of 2:1.\n",
    "# Negative edges during training will be generated on-the-fly.\n",
    "# We can leverage the `RandomLinkSplit()` transform for this from PyG:\n",
    "transform = T.RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    disjoint_train_ratio=0.3,\n",
    "    neg_sampling_ratio=2.0,\n",
    "    add_negative_train_samples=True,\n",
    ")\n",
    "train_data, val_data, test_data = transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeGCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels):\n",
    "        super(EdgeGCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        # Edge prediction MLP\n",
    "        self.edge_mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(2 * hidden_channels, hidden_channels),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_channels, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # First GCN layer\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        # Second GCN layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        # Apply MLP to pairs of node embeddings to predict edges\n",
    "        row, col = edge_index\n",
    "        edge_feat = torch.cat([x[row], x[col]], dim=1)\n",
    "        return self.edge_mlp(edge_feat).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EdgeGCN(128, hidden_channels=16).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing METIS partitioning...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "cluster_data = ClusterData(train_data, num_parts=2, recursive=False)\n",
    "train_loader = ClusterLoader(cluster_data, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GlobalStorage' object has no attribute 'train_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/arnuv/cluster_gcn_amazon.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.141.220.170/home/arnuv/cluster_gcn_amazon.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Training loop\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.141.220.170/home/arnuv/cluster_gcn_amazon.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m300\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B34.141.220.170/home/arnuv/cluster_gcn_amazon.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     loss \u001b[39m=\u001b[39m train()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.141.220.170/home/arnuv/cluster_gcn_amazon.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Loss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/home/arnuv/cluster_gcn_amazon.ipynb Cell 11\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B34.141.220.170/home/arnuv/cluster_gcn_amazon.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m edge_pred \u001b[39m=\u001b[39m model(batch\u001b[39m.\u001b[39mx, batch\u001b[39m.\u001b[39medge_index)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B34.141.220.170/home/arnuv/cluster_gcn_amazon.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Use only the edges used for supervision\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B34.141.220.170/home/arnuv/cluster_gcn_amazon.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m train_edges \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39medge_label_index[:, batch\u001b[39m.\u001b[39;49mtrain_mask]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.141.220.170/home/arnuv/cluster_gcn_amazon.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m labels \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39medge_label[batch\u001b[39m.\u001b[39mtrain_mask]\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B34.141.220.170/home/arnuv/cluster_gcn_amazon.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mbinary_cross_entropy_with_logits(edge_pred[train_edges], labels)\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/torch_geometric/data/data.py:482\u001b[0m, in \u001b[0;36mData.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_store\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[1;32m    477\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    478\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m\u001b[39m object was created by an older version of PyG. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    479\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIf this error occurred while loading an already existing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    480\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdataset, remove the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mprocessed/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m directory in the dataset\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    481\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mroot folder and try again.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 482\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_store, key)\n",
      "File \u001b[0;32m~/venv/lib/python3.9/site-packages/torch_geometric/data/storage.py:87\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[key]\n\u001b[1;32m     86\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m---> 87\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m     88\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     89\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GlobalStorage' object has no attribute 'train_mask'"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        edge_pred = model(batch.x, batch.edge_index)\n",
    "        # Use only the edges used for supervision\n",
    "        train_edges = batch.edge_label_index[:, batch.train_mask]\n",
    "        labels = batch.edge_label[batch.train_mask].float()\n",
    "        loss = F.binary_cross_entropy_with_logits(edge_pred[train_edges], labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(300):\n",
    "    loss = train()\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
