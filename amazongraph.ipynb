{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.nn import functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, roc_auc_score\n",
    "import os\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch_geometric.utils import to_undirected, negative_sampling, add_self_loops\n",
    "from torch_geometric.nn import GraphSAGE, GAT, GIN\n",
    "\n",
    "import torch\n",
    "from torch_geometric.utils import to_undirected\n",
    "from torch_geometric.data import Data\n",
    "import random\n",
    "from collections import defaultdict, deque\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_co_purchase_df = pd.read_csv('kcore70new.csv')\n",
    "processed_co_purchase_df = pd.read_csv('kcore5new.csv')\n",
    "processed_co_purchase_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asin_list = list(processed_co_purchase_df['asin'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_embeddings = np.load(\"image_embeddings_k_5.npy\")\n",
    "text_embeddings = np.load(\"text_embeddings_k_5.npy\")\n",
    "edge_index = np.load(\"k5_edge_index.npy\")\n",
    "\n",
    "# image_embeddings = np.load(\"image_embeddings.npy\")\n",
    "# text_embeddings = np.load(\"text_embeddings.npy\")\n",
    "# edge_index = np.load(\"kcore70newedges.npy\")\n",
    "random_embeddings = torch.randn_like(torch.tensor(text_embeddings.astype(np.float32))) / 10\n",
    "\n",
    "combined_embedings = np.concatenate((image_embeddings, text_embeddings), axis = 1)\n",
    "product_feature_dim = 1024\n",
    "num_products = len(asin_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import to_undirected\n",
    "\n",
    "\n",
    "data = Data(x=torch.tensor(combined_embedings.astype(np.float32)), edge_index=torch.tensor(edge_index))\n",
    "# data = Data(x=combined_embedings, edge_index=torch.tensor(edge_index))\n",
    "\n",
    "data.edge_index = to_undirected(data.edge_index)\n",
    "\n",
    "# For this, we first split the set of edges into\n",
    "# training (80%), validation (10%), and testing edges (10%).\n",
    "# Across the training edges, we use 70% of edges for message passing,\n",
    "# and 30% of edges for supervision.\n",
    "# We further want to generate fixed negative edges for evaluation with a ratio of 2:1.\n",
    "# Negative edges during training will be generated on-the-fly.\n",
    "# We can leverage the `RandomLinkSplit()` transform for this from PyG:\n",
    "transform = T.RandomLinkSplit(\n",
    "    num_val=0.05,\n",
    "    num_test=0.05,\n",
    "    is_undirected=True,\n",
    "    neg_sampling_ratio = 0.0,\n",
    "    add_negative_train_samples=False,\n",
    "    disjoint_train_ratio=0.2)\n",
    "train_data, val_data, test_data = transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_edge_index_to_adj_list(edge_index):\n",
    "    adj_list = defaultdict(list)\n",
    "    for src, dest in zip(edge_index[0], edge_index[1]):\n",
    "        adj_list[src.item()].append(dest.item())\n",
    "    return adj_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the first hop, we sample at most 20 neighbors.\n",
    "# In the second hop, we sample at most 10 neighbors.\n",
    "# In addition, during training, we want to sample negative edges on-the-fly with\n",
    "# a ratio of 2:1.\n",
    "# We can make use of the `loader.LinkNeighborLoader` from PyG:\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "# Define seed edges:\n",
    "train_loader = LinkNeighborLoader(\n",
    "    data=train_data,\n",
    "    num_neighbors=[10, 10, 10],\n",
    "    edge_label_index=train_data.edge_label_index,\n",
    "    edge_label=train_data.edge_label,\n",
    "    neg_sampling_ratio=4,\n",
    "    batch_size=256,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_loader = LinkNeighborLoader(\n",
    "    data = val_data, \n",
    "    num_neighbors=[10, 10, 10],\n",
    "    edge_label_index=val_data.edge_label_index,\n",
    "    edge_label=val_data.edge_label,\n",
    "    batch_size = 1,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "test_loader = LinkNeighborLoader(\n",
    "    data = test_data, \n",
    "    num_neighbors=[10, 10, 10],\n",
    "    edge_label_index=test_data.edge_label_index,\n",
    "    edge_label=test_data.edge_label,\n",
    "    batch_size = 1,\n",
    "    shuffle = True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_edge_index_to_adj_list(edge_index):\n",
    "    adj_list = defaultdict(list)\n",
    "    for src, dest in zip(edge_index[0], edge_index[1]):\n",
    "        adj_list[src.item()].append(dest.item())\n",
    "    return adj_list\n",
    "\n",
    "def bfs_sample(adj_list, start_node, max_depth):\n",
    "    visited = set()\n",
    "    queue = deque([(start_node, 0)])\n",
    "    visited.add(start_node)\n",
    "    \n",
    "    while queue:\n",
    "        current_node, depth = queue.popleft()\n",
    "        if depth == max_depth:\n",
    "            return current_node\n",
    "        \n",
    "        for neighbor in adj_list[current_node]:\n",
    "            if neighbor not in visited:\n",
    "                visited.add(neighbor)\n",
    "                queue.append((neighbor, depth + 1))\n",
    "    \n",
    "    return None\n",
    "\n",
    "def add_bfs_negatives(data, m=3, k=3):\n",
    "    adj_list = convert_edge_index_to_adj_list(data.edge_index)\n",
    "    new_edges = []\n",
    "    new_labels = []\n",
    "    new_edge_label_index = []\n",
    "\n",
    "    for edge in tqdm(range(data.edge_label_index.size(1))):\n",
    "        start_nodes = [data.edge_label_index[0, edge].item(), data.edge_label_index[1, edge].item()]\n",
    "        for start_node in start_nodes:\n",
    "            for _ in range(k):\n",
    "                depth = random.randint(2, m)\n",
    "                neg_node = bfs_sample(adj_list, start_node, depth)\n",
    "                if neg_node is not None and neg_node not in adj_list[start_node]:\n",
    "                    new_edges.append([start_node, neg_node])\n",
    "                    new_labels.append(0)  # Label for negative samples\n",
    "                    new_edge_label_index.append([start_node, neg_node])\n",
    "\n",
    "    new_edges = torch.tensor(new_edges, dtype=torch.long).t()\n",
    "    new_labels = torch.tensor(new_labels, dtype=torch.float)\n",
    "    new_edge_label_index = torch.tensor(new_edge_label_index, dtype=torch.long).t()\n",
    "\n",
    "    data.edge_index = torch.cat([data.edge_index, new_edges], dim=1)\n",
    "    data.edge_label = torch.cat([data.edge_label, new_labels])\n",
    "    data.edge_label_index = torch.cat([data.edge_label_index, new_edge_label_index], dim=1)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = GraphSAGE(\n",
    "    in_channels=product_feature_dim,\n",
    "    hidden_channels=256,\n",
    "    out_channels=256,\n",
    "    dropout = 0.1,\n",
    "    project = True,\n",
    "    num_layers=3).to(device)\n",
    "    \n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = GAT(\n",
    "    in_channels=product_feature_dim,\n",
    "    hidden_channels=256,\n",
    "    out_channels=256,\n",
    "    num_layers = 3,\n",
    "    dropout = 0.1,\n",
    "    heads=2).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GIN(\n",
    "    in_channels = product_feature_dim, \n",
    "    hidden_channels=256,\n",
    "    out_channels = 256,\n",
    "    dropout = 0.1,\n",
    "    num_layers = 3\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"gin_baseline\"  # replace with your experiment name\n",
    "num_iters = 500\n",
    "logging_freq = 50\n",
    "num_val_batch_sample = 20\n",
    "num_epochs = 1\n",
    "top_k = 4\n",
    "os.makedirs(experiment_name, exist_ok=True)\n",
    "writer = SummaryWriter(log_dir=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_logits(model, batch):\n",
    "    z = model(batch.x, batch.edge_index)\n",
    "\n",
    "    head_embeddings = z[batch.edge_label_index[0]]\n",
    "    head_embeddings = head_embeddings / head_embeddings.norm(dim = 1, keepdim = True)\n",
    "\n",
    "    tail_embeddings = z[batch.edge_label_index[1]]\n",
    "    tail_embeddings = tail_embeddings / tail_embeddings.norm(dim = 1, keepdim = True)\n",
    "\n",
    "\n",
    "    link_logits = (head_embeddings * tail_embeddings).sum(dim=1)\n",
    "\n",
    "\n",
    "    return link_logits\n",
    "\n",
    "def get_embeddings(model, batch):\n",
    "    z = model(batch.x, batch.edge_index)\n",
    "    z = z / z.norm(dim=1, keepdim=True)  # Normalizing embeddings\n",
    "    return z\n",
    "\n",
    "def compute_dot_products(embeddings, head_node_index):\n",
    "    head_embedding = embeddings[head_node_index]\n",
    "    dot_products = torch.matmul(embeddings, head_embedding.unsqueeze(-1)).squeeze(-1)\n",
    "    return dot_products\n",
    "\n",
    "\n",
    "def recall_at_k(dot_products, actual_tail_index, k=10):\n",
    "    print(dot_products.shape)\n",
    "    top_k_scores, top_k_indices = torch.topk(dot_products, k)\n",
    "    return 1 if actual_tail_index in top_k_indices else 0\n",
    "\n",
    "\n",
    "\n",
    "def bpr_loss(pos_score, neg_scores):\n",
    "    return -torch.log(torch.sigmoid(pos_score - neg_scores)).mean()\n",
    "\n",
    "\n",
    "total_loss = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, batch in tqdm(enumerate(train_loader)):\n",
    "\n",
    "        print(batch)\n",
    "\n",
    "\n",
    "        # batch = add_bfs_negatives(batch)\n",
    "        if i % logging_freq == 0:\n",
    "            recall_at_k_scores = []\n",
    "\n",
    "            for _ in range(num_val_batch_sample):\n",
    "                val_sample = next(iter(val_loader))\n",
    "                val_sample.to(device)\n",
    "\n",
    "\n",
    "                embeddings = get_embeddings(model, val_sample)\n",
    "\n",
    "                head_node_index = val_sample.edge_label_index[0, 0]  # Assuming single label per batch\n",
    "                actual_tail_index = val_sample.edge_label_index[1, 0]\n",
    "\n",
    "                dot_products = compute_dot_products(embeddings, head_node_index)\n",
    "                recall_at_k_score = recall_at_k(dot_products, actual_tail_index, k=top_k)\n",
    "\n",
    "                recall_at_k_scores.append(recall_at_k_score)\n",
    "\n",
    "            recallk = np.mean(recall_at_k_scores)\n",
    "\n",
    "            \n",
    "            writer.add_scalar('Recall at K', recallk, i)\n",
    "            torch.save(model.state_dict(), os.path.join(experiment_name, f'checkpoint_{i}.pth'))\n",
    "\n",
    "        batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_logits = recover_logits(model, batch)\n",
    "        train_labels = batch.edge_label.float()\n",
    "\n",
    "        loss = F.binary_cross_entropy_with_logits(train_logits, train_labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        writer.add_scalar('Loss', loss.item(), i)\n",
    "\n",
    "\n",
    "        if i == num_iters:\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1157])\n",
      "torch.Size([1020])\n",
      "torch.Size([375])\n",
      "torch.Size([992])\n",
      "torch.Size([980])\n",
      "torch.Size([801])\n",
      "torch.Size([1430])\n",
      "torch.Size([727])\n",
      "torch.Size([1015])\n",
      "torch.Size([1290])\n",
      "torch.Size([473])\n",
      "torch.Size([645])\n",
      "torch.Size([859])\n",
      "torch.Size([1156])\n",
      "torch.Size([1001])\n",
      "torch.Size([1068])\n",
      "torch.Size([224])\n",
      "torch.Size([1396])\n",
      "torch.Size([508])\n",
      "torch.Size([792])\n",
      "torch.Size([147])\n",
      "torch.Size([1470])\n",
      "torch.Size([395])\n",
      "torch.Size([592])\n",
      "torch.Size([886])\n",
      "torch.Size([1026])\n",
      "torch.Size([966])\n",
      "torch.Size([1402])\n",
      "torch.Size([1100])\n",
      "torch.Size([1178])\n",
      "torch.Size([960])\n",
      "torch.Size([868])\n",
      "torch.Size([741])\n",
      "torch.Size([903])\n",
      "torch.Size([765])\n",
      "torch.Size([57])\n",
      "torch.Size([1170])\n",
      "torch.Size([1347])\n",
      "torch.Size([1146])\n",
      "torch.Size([654])\n",
      "torch.Size([815])\n",
      "torch.Size([1056])\n",
      "torch.Size([1106])\n",
      "torch.Size([826])\n",
      "torch.Size([1486])\n",
      "torch.Size([900])\n",
      "torch.Size([1036])\n",
      "torch.Size([1557])\n",
      "torch.Size([1198])\n",
      "torch.Size([1205])\n",
      "torch.Size([1452])\n",
      "torch.Size([1144])\n",
      "torch.Size([1187])\n",
      "torch.Size([941])\n",
      "torch.Size([1145])\n",
      "torch.Size([1418])\n",
      "torch.Size([931])\n",
      "torch.Size([1074])\n",
      "torch.Size([1278])\n",
      "torch.Size([1242])\n",
      "torch.Size([743])\n",
      "torch.Size([984])\n",
      "torch.Size([901])\n",
      "torch.Size([664])\n",
      "torch.Size([675])\n",
      "torch.Size([799])\n",
      "torch.Size([1417])\n",
      "torch.Size([1108])\n",
      "torch.Size([1328])\n",
      "torch.Size([416])\n",
      "torch.Size([369])\n",
      "torch.Size([1357])\n",
      "torch.Size([1083])\n",
      "torch.Size([1578])\n",
      "torch.Size([947])\n",
      "torch.Size([780])\n",
      "torch.Size([1529])\n",
      "torch.Size([1468])\n",
      "torch.Size([1428])\n",
      "torch.Size([415])\n",
      "torch.Size([1277])\n",
      "torch.Size([427])\n",
      "torch.Size([1259])\n",
      "torch.Size([1443])\n",
      "torch.Size([823])\n",
      "torch.Size([851])\n",
      "torch.Size([1149])\n",
      "torch.Size([1448])\n",
      "torch.Size([694])\n",
      "torch.Size([921])\n",
      "torch.Size([671])\n",
      "torch.Size([905])\n",
      "torch.Size([351])\n",
      "torch.Size([810])\n",
      "torch.Size([367])\n",
      "torch.Size([771])\n",
      "torch.Size([1351])\n",
      "torch.Size([1296])\n",
      "torch.Size([1443])\n",
      "torch.Size([1094])\n",
      "torch.Size([1182])\n",
      "torch.Size([859])\n",
      "torch.Size([582])\n",
      "torch.Size([1281])\n",
      "torch.Size([933])\n",
      "torch.Size([1422])\n",
      "torch.Size([386])\n",
      "torch.Size([1034])\n",
      "torch.Size([1401])\n",
      "torch.Size([368])\n",
      "torch.Size([718])\n",
      "torch.Size([791])\n",
      "torch.Size([1195])\n",
      "torch.Size([700])\n",
      "torch.Size([1262])\n",
      "torch.Size([1487])\n",
      "torch.Size([1418])\n",
      "torch.Size([629])\n",
      "torch.Size([1452])\n",
      "torch.Size([978])\n",
      "torch.Size([1459])\n",
      "torch.Size([1157])\n",
      "torch.Size([947])\n",
      "torch.Size([949])\n",
      "torch.Size([635])\n",
      "torch.Size([323])\n",
      "torch.Size([309])\n",
      "torch.Size([1335])\n",
      "torch.Size([1350])\n",
      "torch.Size([1471])\n",
      "torch.Size([1320])\n",
      "torch.Size([961])\n",
      "torch.Size([1599])\n",
      "torch.Size([1472])\n",
      "torch.Size([423])\n",
      "torch.Size([975])\n",
      "torch.Size([356])\n",
      "torch.Size([1163])\n",
      "torch.Size([1170])\n",
      "torch.Size([1215])\n",
      "torch.Size([1161])\n",
      "torch.Size([1203])\n",
      "torch.Size([1407])\n",
      "torch.Size([721])\n",
      "torch.Size([1346])\n",
      "torch.Size([643])\n",
      "torch.Size([917])\n",
      "torch.Size([934])\n",
      "torch.Size([225])\n",
      "torch.Size([1102])\n",
      "torch.Size([1039])\n",
      "torch.Size([997])\n",
      "torch.Size([1012])\n",
      "torch.Size([674])\n",
      "torch.Size([1290])\n",
      "torch.Size([430])\n",
      "torch.Size([822])\n",
      "torch.Size([325])\n",
      "torch.Size([735])\n",
      "torch.Size([1332])\n",
      "torch.Size([1040])\n",
      "torch.Size([1203])\n",
      "torch.Size([641])\n",
      "torch.Size([973])\n",
      "torch.Size([1149])\n",
      "torch.Size([1455])\n",
      "torch.Size([834])\n",
      "torch.Size([154])\n",
      "torch.Size([622])\n",
      "torch.Size([239])\n",
      "torch.Size([1063])\n",
      "torch.Size([325])\n",
      "torch.Size([1480])\n",
      "torch.Size([1163])\n",
      "torch.Size([695])\n",
      "torch.Size([912])\n",
      "torch.Size([780])\n",
      "torch.Size([1399])\n",
      "torch.Size([1007])\n",
      "torch.Size([1347])\n",
      "torch.Size([1082])\n",
      "torch.Size([1274])\n",
      "torch.Size([897])\n",
      "torch.Size([341])\n",
      "torch.Size([722])\n",
      "torch.Size([1640])\n",
      "torch.Size([1440])\n",
      "torch.Size([413])\n",
      "torch.Size([1185])\n",
      "torch.Size([1351])\n",
      "torch.Size([927])\n",
      "torch.Size([1024])\n",
      "torch.Size([1273])\n",
      "torch.Size([847])\n",
      "torch.Size([1146])\n",
      "torch.Size([1025])\n",
      "torch.Size([798])\n",
      "torch.Size([816])\n",
      "torch.Size([935])\n",
      "torch.Size([1130])\n",
      "Average Recall at K: 0.02\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables for calculating average recall at k\n",
    "total_recall_at_k = 0\n",
    "num_test_batches = 0\n",
    "\n",
    "# Iterate through the test_loader\n",
    "for test_batch in test_loader:\n",
    "    num_test_batches += 1\n",
    "    test_batch.to(device)\n",
    "\n",
    "    # Get embeddings for the test batch\n",
    "    embeddings = get_embeddings(model, test_batch)\n",
    "\n",
    "    # Assuming you are interested in the first edge in each batch for recall calculation\n",
    "    head_node_index = test_batch.edge_label_index[0, 0] \n",
    "    actual_tail_index = test_batch.edge_label_index[1, 0]\n",
    "\n",
    "    # Compute dot products and recall at k for the test batch\n",
    "    dot_products = compute_dot_products(embeddings, head_node_index)\n",
    "    recall_at_k_score = recall_at_k(dot_products, actual_tail_index, k=top_k)  # You can adjust k as needed\n",
    "\n",
    "    # Update total recall at k score\n",
    "    total_recall_at_k += recall_at_k_score\n",
    "\n",
    "    if num_test_batches == 200:\n",
    "        break\n",
    "\n",
    "# Calculate and print the average recall at k\n",
    "average_recall_at_k = total_recall_at_k / num_test_batches\n",
    "print(f'Average Recall at K: {average_recall_at_k}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
