{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "import warnings\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load product information and co-purchase edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_details_df = pd.read_csv('amazon_dataset/clothing_shoes_jewellery/all_products.csv')\n",
    "all_details_df.set_index('asin', inplace=True)\n",
    "\n",
    "co_purchase_df = pd.read_csv('bidirectional_links.csv') # co-purchase edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snippet to create the bidirectional co-purchase edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_amazon_data(input_df):\n",
    "    # Function to safely convert string to list\n",
    "    def convert_string_to_list(string):\n",
    "        try:\n",
    "            return ast.literal_eval(string)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "\n",
    "    # Step 1: Convert string representation of list to actual list and then expand\n",
    "    expanded_rows = []\n",
    "    for index, row in input_df.iterrows():\n",
    "        root_asin = row['asin']\n",
    "        also_bought_list = convert_string_to_list(row['also_bought'])\n",
    "        if also_bought_list:\n",
    "            for also_bought_asin in also_bought_list:\n",
    "                expanded_rows.append({'asin': root_asin, 'also_bought': also_bought_asin})\n",
    "\n",
    "    expanded_df = pd.DataFrame(expanded_rows)\n",
    "\n",
    "    # Step 2: Create reverse pairs\n",
    "    reverse_pairs = expanded_df.rename(columns={'asin': 'also_bought', 'also_bought': 'asin'})\n",
    "\n",
    "    # Step 3: Combine and remove duplicates\n",
    "    combined_df = pd.concat([expanded_df, reverse_pairs]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a 5-core co-purchase graph. Each product in the graph will have atleast 5 edges. \n",
    "\n",
    "###### Note that this graph is not cleaned yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_to_k_core(co_purchase_df, k=5):\n",
    "    while True:\n",
    "        # Count connections for each ASIN\n",
    "        connection_counts = co_purchase_df['asin'].value_counts().add(co_purchase_df['also_bought'].value_counts(), fill_value=0)\n",
    "\n",
    "        # Identify nodes with fewer than k connections\n",
    "        underconnected_nodes = set(connection_counts[connection_counts < k].index)\n",
    "\n",
    "        if not underconnected_nodes:\n",
    "            break\n",
    "\n",
    "        # Filter out rows where ASINs have fewer than k connections\n",
    "        co_purchase_df = co_purchase_df[~co_purchase_df['asin'].isin(underconnected_nodes) & ~co_purchase_df['also_bought'].isin(underconnected_nodes)]\n",
    "\n",
    "    return co_purchase_df\n",
    "\n",
    "k_core_df = reduce_to_k_core(co_purchase_df)\n",
    "k_core_df.set_index('asin', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 407672/407672 [00:21<00:00, 19195.19it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_image_list(image_folder):\n",
    "    return set(os.listdir(image_folder))\n",
    "\n",
    "def has_required_data(product, required_columns):\n",
    "    if product.empty:\n",
    "        return False\n",
    "    return all(isinstance(product[col], str) for col in required_columns)\n",
    "\n",
    "def is_image_valid(product, image_list):\n",
    "    if product.empty or product['imUrl'] is None or pd.isna(product['imUrl']):\n",
    "        return False\n",
    "\n",
    "    image_name = product['imUrl'].split('/')[-1]\n",
    "    return image_name in image_list\n",
    "\n",
    "def is_asin_valid(asin, co_purchase_df, all_details_df, image_list, required_columns):\n",
    "    product = all_details_df.loc[asin]\n",
    "    if has_required_data(product, required_columns) and is_image_valid(product, image_list):\n",
    "        return asin\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def process_asins(co_purchase_df, all_details_df, image_list, required_columns):\n",
    "    valid_asins = set()\n",
    "    asins = co_purchase_df.index.unique()\n",
    "\n",
    "    for asin in tqdm(asins):\n",
    "        result = is_asin_valid(asin, co_purchase_df, all_details_df, image_list, required_columns)\n",
    "        if result:\n",
    "            valid_asins.add(result)\n",
    "\n",
    "    return valid_asins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-core graph is cleaned to remove products with missing image, title and brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create image list and list of valid ASINs\n",
    "image_list = get_image_list('/home/arnuv/amazon_dataset/clothing_shoes_jewellery/images')\n",
    "valid_asins = process_asins(k_core_df, all_details_df, image_list, ['title', 'imUrl', 'brand'])\n",
    "\n",
    "# Step 2: Create masks for both 'asin' and 'also_bought'\n",
    "k_core_df = k_core_df.reset_index()\n",
    "asin_mask = k_core_df['asin'].isin(valid_asins)\n",
    "also_bought_mask = k_core_df['also_bought'].apply(lambda x: x in valid_asins)\n",
    "combined_mask = asin_mask & also_bought_mask\n",
    "filtered_df = k_core_df[combined_mask]\n",
    "filtered_df.to_csv('kcore5new_brand.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AsinIdMap:\n",
    "    def __init__(self, asin_list):\n",
    "        self.asin_list = asin_list\n",
    "        self.asin_to_idx = {}\n",
    "        self.product_idx_to_asin = {}\n",
    "        self._build()\n",
    "    \n",
    "    def _build(self):\n",
    "        for idx, asin in enumerate(self.asin_list):\n",
    "            self.asin_to_idx[asin] = idx\n",
    "            self.product_idx_to_asin[idx] = asin\n",
    "    \n",
    "    def get_idx(self, asin):\n",
    "        return self.asin_to_idx[asin]\n",
    "    \n",
    "    def get_asin(self, product_idx):\n",
    "        return self.product_idx_to_asin[product_idx]\n",
    "    \n",
    "    def get_count(self):\n",
    "        return len(self.asin_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the k-core graph into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_5_csv = pd.read_csv('kcore5new_brand.csv')\n",
    "\n",
    "asin_list = list(k_5_csv['asin'].unique())\n",
    "asinIdLookup = AsinIdMap(asin_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and store the edge list for the 5-core graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_product_to_product_edge_index(edges_pd, asin_id_map, right_key):\n",
    "    product_to_product_edge_index = []\n",
    "    for idx, row in tqdm(edges_pd.iterrows()):\n",
    "            asin1 = row['asin']\n",
    "            product1_idx = asin_id_map.get_idx(asin1)\n",
    "            asin2 = row[right_key]\n",
    "            product2_idx = asin_id_map.get_idx(asin2)\n",
    "            if product1_idx == product2_idx:\n",
    "                continue\n",
    "            product_to_product_edge_index.append([product1_idx, product2_idx])\n",
    "\n",
    "    return torch.tensor(product_to_product_edge_index).t().contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2183it [00:00, 21825.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "574160it [00:26, 21319.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge shape:  torch.Size([2, 574160])\n"
     ]
    }
   ],
   "source": [
    "edge_index = build_product_to_product_edge_index(k_5_csv, asinIdLookup, 'also_bought')\n",
    "print(\"Edge shape: \", edge_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"k5_edge_index_brand.npy\", edge_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
